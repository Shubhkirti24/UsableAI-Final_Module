{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting the Best out of LLM's\n",
    "___\n",
    "\n",
    "Welcome to the module on Prompt Engineering! This course is designed to help you understand how to interact with large language models (LLMs) like ChatGPT effectively by structuring your prompts to get the best possible outcomes. Let's delve into the world of prompt engineering by first understanding the basics of prompt effectiveness and then exploring advanced prompting techniques.\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## What is the Large-Language-Model (LLM)?\n",
    "* Definition: LLMs are advanced ***generative models*** designed to understand, generate, and interact with human language by processing vast amounts of text data. There are popular models like OpenAI's GPT series, Google's BERT, and others - these models are trained on diverse datasets and their capabilities in various tasks such as text completion, translation, and summarization.\n",
    "* What is ***generative model***?\n",
    "    * Generative models are a class of AI that learns to generate new data instances that resemble the training data using probablistic model. Here, LLM's training data is large and general natural language, so the output of LLM is a resemblence of these data.\n",
    "    * Because of these \"generative\" and \"probablistic\" features of the LLM, LLM can generate very diverse and plausible natural language outputs. However, there is a catch in \"plausible.\" As all deep learning models are based on probablistic model, it is not deterministic and can cause hallucination. It can be \"plausible\", not incorrect. Also, LLMs are known to be weak in deterministic logics.\n",
    "    * Here is the famous artifacts ([ref](https://medium.com/merzazine/drawing-hands-and-ai-78b501df0085)) in early vision generative model. It's plausible (we know it is drawing of hands), but incorrect. This happens in LLMs as well.\n",
    "        <p align=\"center\">\n",
    "          <img src=\"famous_finger_artifact.webp\" />\n",
    "        </p>\n",
    "* Overall, LLMs are very powerful and productive tool. But we should be careful when using this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: The Importance of Effective Prompting\n",
    "\n",
    "___\n",
    "\n",
    "### Objective: Understand how accurate prompts enhance the interaction with LLMs.\n",
    "\n",
    "#### 1.1 Understanding LLMs and Prompt Responsiveness\n",
    "Large Language Models (LLMs), such as ChatGPT, are trained on diverse datasets to generate text-based responses. These models respond based on patterns and information learned during training. The effectiveness of these responses heavily depends on how the prompts are structured. An accurately crafted prompt leads to responses that are more relevant, precise, and useful.\n",
    "\n",
    "Most of popular models you see out there, for instance GPT-4, Claude 3,  are `text generation` models, which means they are effectively based on next word prediction. These models are then trained by using various datasets for Q/A tasks, which makes them so simple and effective to chat with.\n",
    "\n",
    "We will use these techniques, i.e the one which were used for teaching these models Q/A to extract the information we need. Before we actually start with the 'HOW' let's start with the 'WHAT' for these models.\n",
    "\n",
    "\n",
    "#### 1.2 Key Elements of an Effective Prompt\n",
    "- `Clarity:` Clear and concise prompts lead to better understanding and responses.\n",
    "        - Structuring the prompt is very important to get the best possible results from the LLM.\n",
    "        - Don't be afraid to use : `Shit + Enter`. What is does move the cursor to the next line. It helps you and the model to structure understand the task.\n",
    "\n",
    "- `Specificity:` Detailed prompts provide models with a better scope and context, reducing ambiguity.\n",
    "\n",
    "- `Intent:` Expressing the intent of your query clearly helps the model generate the most appropriate response.\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Techniques to Reduce Hallucination in LLMs\n",
    "___\n",
    "\n",
    "### Objective: Learn techniques that minimize inaccuracies and fabrications in model responses.\n",
    "\n",
    "Hallucination in LLMs refers to instances where the model generates false or unverifiable information. This section will cover strategies to minimize this phenomenon.\n",
    "\n",
    "In order to reduce model hallucination it is important to form a structure what you want from the model. The final responses can be simply classified into a few tasks:\n",
    "- **Informational**: Is it information that you need? \n",
    "(P.S. Google might still be a better option for this as the model's knowledge needs to be augmented in the form of adding context or a information retrieval system before it can actually provide you with accurate information)\n",
    "\n",
    "- **Task Processing** : LLM's excel at this task, pun intended. The main aim of this module is to make you better at utilizing these capabilities that can aid you in work.\n",
    "\n",
    "\n",
    "#### 2.1 Precision in Prompting\n",
    "Ensuring your prompt is direct and includes all necessary details can significantly reduce hallucination by focusing the modelâ€™s \"attention\" on the specifics rather than allowing it to generate broader, potentially inaccurate content.\n",
    "\n",
    "#### 2.2 Iterative Refinement\n",
    "Refining the response through follow-up prompts can help correct and focus the output, steering the model away from potential hallucinations.\n",
    "\n",
    "#### 2.3 Giving the model time to think : What you give is what you get!\n",
    "Consider ChatGPT to be an actor, employed by you. It will get into any role that you desire it to be in, but it will only provide for what you ask for. The following technique will help ypu communicate with the 'actor' and get the response you need.\n",
    "\n",
    "Split the prompt into clear sections, namely :\n",
    "- `Role`: **DEFINE the role clearly**, for instance, 'I want you to act as a data science instructor' or ' I want you to act as a software developer. Please help me improve the time complexity of the code below.'\n",
    "- `Aim` : **EXPLAIN the boundaries of your problem**, for instance, 'Your aim is to explain why the following code is giving me the following error and give me the correct code using Python'\n",
    "- `Context` : **Add the background**, this will help the model to understand the context behind the prompt. For instance 'The following code was written in python using pandas and NumPy.'\n",
    "- `Example Output` : **Add Examples**, this is for the model to structure it's response to your prompt. A simple example goes a long way. For instance, 'Write the code in the following JSON Format : '\n",
    "\n",
    "Here's what the before and after looks like :\n",
    "\n",
    "\n",
    "Initial Prompt : Give me a code for linear regression in python for house price prediction dataset.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"Before.png\" />\n",
    "</p>\n",
    "\n",
    "\n",
    "Modified Prompt :\n",
    "\n",
    "- `Role` : 'I want you to act as a data science instructor'\n",
    "- `Aim`  : 'Your aim is to write an optimized code using multi-processing in python using scikit-learn, numpy and pandas for linear regression for house price prediction with comments to explain the code.'\n",
    "- `Context`: 'The dataset contains the following features 'Area','Number of bedrooms', 'number of washrooms' and the target variable 'Price' '\n",
    "- `Example Output`: The output should contain stepwise feature processing techniques like scaling for each of features like :\n",
    "1. Step 1 : 'Area'\n",
    "2. Step 2 : 'Number of bedrooms' ,.. and so on\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"After.png\" />\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"After_2.png\" />\n",
    "</p>\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Advanced Prompting Techniques\n",
    "\n",
    "___\n",
    "\n",
    "### Objective: Explore various advanced techniques to structure prompts that enhance the effectiveness of LLM interactions.\n",
    "\n",
    "- The techniques listed below are an emulation for what was used to essentially 'train' or 'finetune' the model. You can essentially play around with them and see which model performs better with which one. Every model is trained differently, with different datasets and different techniques. Sometimes, you may find that a combination of the following helps you create the most effective prompts for a given model. The way ChatGPT responds to a question, might not the be the way Claude responds to it. \n",
    "\n",
    "- Understanding these techniques will help you incorporate a few main ideas that can later help you finetune a model for your own task on your own dataset!\n",
    "\n",
    "#### 3.1 Zero-Shot Learning\n",
    "- In-Depth Analysis:\n",
    "Zero-shot learning relies on the model's pre-trained capabilities without any example-based learning specific to the task at hand. It leverages the model's inherent knowledge, which has been obtained during its extensive training on a wide range of data and tasks.\n",
    "\n",
    "- Practical Example:\n",
    "If you're looking to quickly gather an overview or a definition, such as \"Explain what blockchain technology is,\" zero-shot learning is effective because the model can draw directly from its pre-trained data without additional context.\n",
    "\n",
    "#### 3.2 Few-Shot Learning\n",
    "- In-Depth Analysis:\n",
    "Few-shot learning improves the model's accuracy on specific tasks by providing a few examples at the time of inference. This helps the model understand the context or format better, essentially giving it a 'hint' of what is expected.\n",
    "\n",
    "- Practical Example:\n",
    "When you want the model to categorize customer feedback into themes, you can provide examples of categorized feedback, like:\n",
    "\n",
    "\"The service was fast and friendly.\" - Positive\n",
    "\"It took too long to receive assistance.\" - Negative\n",
    "This helps the model apply these themes more accurately to new feedback.\n",
    "\n",
    "#### 3.3 Chain of Thought Prompting\n",
    "- In-Depth Analysis:\n",
    "Chain of thought prompting encourages the model to articulate its reasoning step by step. This method is particularly useful in educational settings or complex problem-solving scenarios where understanding the reasoning process is as important as the answer itself.\n",
    "\n",
    "- Practical Example:\n",
    "For a math problem like \"What is 58 divided by 6?\" a chain of thought response might be:\n",
    "\n",
    "\"First, I calculate how many times 6 fits into 58.\"\n",
    "\"6 times 9 is 54, which is close to 58.\"\n",
    "\"58 minus 54 leaves a remainder of 4.\"\n",
    "\"So, the answer is 9 remainder 4.\"\n",
    "\n",
    "#### 3.4 Generate Knowledge Prompting\n",
    "- In-Depth Analysis:\n",
    "Generate knowledge prompting involves the model generating new insights or synthesizing information from its training to provide enriched responses. This technique is particularly valuable when existing data might be incomplete or when innovation is required.\n",
    "\n",
    "- Practical Example:\n",
    "In a scenario where a new product is introduced in the market, you could ask, \"Predict the potential impacts of the new energy-efficient refrigerator on the market trends,\" helping to simulate forecasts and innovative thinking.\n",
    "\n",
    "#### 3.5 Prompt Chaining\n",
    "- In-Depth Analysis:\n",
    "Prompt chaining involves using the response of one query as the input for another. This method can guide a discussion or exploration of a topic in depth, allowing for a more structured and extended interaction.\n",
    "\n",
    "- Practical Example:\n",
    "Starting with \"What are the main ingredients in a chocolate cake?\" and then asking, \"Which of these ingredients is responsible for making the cake rise?\" promotes a focused and detailed investigation.\n",
    "\n",
    "#### 3.6 Tree of Thoughts\n",
    "- In-Depth Analysis:\n",
    "Tree of thoughts uses a hierarchical approach to explore different branches of a topic systematically. It's akin to creating a mind map through dialogue with the model, which can cover broad areas systematically.\n",
    "\n",
    "- Practical Example:\n",
    "You might start with \"Explain the human respiratory system,\" and follow with branches like \"Describe the function of the lungs\" and \"What are the consequences of blocked airways?\"\n",
    "\n",
    "#### 3.7 Directional Stimulus Prompting\n",
    "- In-Depth Analysis:\n",
    "This technique involves directing the model to focus on a specific aspect of a broader topic, guiding the response to be more targeted and relevant to a particular subtopic.\n",
    "\n",
    "- Practical Example:\n",
    "Asking, \"Discuss the economic effects of renewable energy adoption,\" focuses the discussion on economic aspects, avoiding broader environmental or technical details.\n",
    "\n",
    "#### 3.8 ReAct Prompting\n",
    "- In-Depth Analysis:\n",
    "ReAct prompting involves revising or asking the model to reconsider its previous responses based on new information or corrections, promoting a dynamic and adaptive dialogue.\n",
    "\n",
    "- Practical Example:\n",
    "If the model states, \"The Eiffel Tower is in Brussels,\" a ReAct prompt might be, \"You mentioned the Eiffel Tower is in Brussels, but it is actually in Paris. How does this affect tourism in Paris?\"\n",
    "\n",
    "#### 3.9 Graph Prompting\n",
    "- In-Depth Analysis:\n",
    "Graph prompting uses graphical data or structured prompts that require the model to consider relationships or hierarchies in its responses, useful for complex decision-making scenarios.\n",
    "\n",
    "- Practical Example:\n",
    "\"Given a graph of population versus carbon emissions by country, identify which countries are the most efficient in terms of emissions per capita.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Section 4: Actual Prompting \n",
    "___\n",
    "\n",
    "### Objective : Creating effective prompts for coding tasks\n",
    "\n",
    "Now that we have actually have a simple understanding of the techniques, let's go ahead and see how these prompting techniques can be used for coding tasks.\n",
    "\n",
    "#### 4.1 : Zero Shot Learning:\n",
    "\n",
    "[Link to the paper](https://arxiv.org/abs/2205.11916)\n",
    "\n",
    "- Summary:\n",
    "\n",
    "Zero-shot learning relies on the model's inherent ability to generalize from its pre-existing knowledge without needing specific examples for the task at hand. This method is particularly useful when you need responses based on broad, general knowledge the model has been trained on.\n",
    "\n",
    "\n",
    "- Example for a Coding Task:\n",
    "\n",
    "`User Prompt:` \"Write Python code to find the factorial of a number.\"\n",
    "\n",
    "`Improved Prompt:` \"Considering your understanding of basic Python syntax and functions, write a function to compute the factorial of a given number.\"\n",
    "\n",
    "`Finally Developed Prompt:` \"Create a Python function named factorial that takes an integer n and returns the factorial of n, using a for loop to calculate the product sequentially.\"\n",
    "\n",
    "`Desired Answer from the LLM:`\n",
    "\n",
    "            def factorial(n):\n",
    "                    if n == 0:\n",
    "                        return 1\n",
    "                    result = 1\n",
    "                    for i in range(2, n + 1):\n",
    "                        result *= i\n",
    "                return result\n",
    "\n",
    "`Try this:` Just add a 'Let's think step by step' into few of the sentences of the prompt and see your responses transform!\n",
    "\n",
    "\n",
    "\n",
    "#### 4.2 : Few-Shot Learning:\n",
    "\n",
    "[Link to the paper](https://arxiv.org/abs/2005.14165)\n",
    "\n",
    "- Summary:\n",
    "Few-shot learning enhances the model's performance by providing it with a few examples that demonstrate what is expected. This method can be particularly effective in tasks where the format or specific output structure is important and can be exemplified through a few samples.\n",
    "\n",
    "- Example for a Machine Learning Task:\n",
    "\n",
    "`User Prompt:` \"How do I split data for machine learning?\"\n",
    "\n",
    "`Improved Prompt:` \"Provide examples of how data is typically split for training and testing in machine learning, then explain how to apply this in Python using sklearn.\"\n",
    "\n",
    "`Finally Developed Prompt:` \"Here are three examples of how data is split in machine learning projects: \n",
    "1) 70% training, 30% testing \n",
    "2) 80% training, 20% testing \n",
    "3) 60% training, 40% testing.\n",
    "Write Python code using sklearn to split data according to the first example.\"\n",
    "\n",
    "`Desired Answer from the LLM:`\n",
    "\n",
    "            from sklearn.model_selection import train_test_split\n",
    "         # Assume X and y are your features and labels\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        # This code splits the dataset into 70% training data and 30% testing data.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/openai/openai-cookbook/main/images/least-to-most_fig1.png\" />\n",
    "</p>\n",
    "\n",
    "\n",
    "#### 4.3 : Chain of Thought Prompting :\n",
    "\n",
    "[Link to the paper](https://arxiv.org/abs/2201.11903) \n",
    "\n",
    "- Summary:\n",
    "Chain of thought prompting involves encouraging the model to process and articulate intermediate steps or reasoning that lead to a final answer. This technique helps in breaking down complex problems and makes the model's reasoning transparent and verifiable.\n",
    "\n",
    "- Example for a Machine Learning Task:\n",
    "\n",
    "`User Prompt`: \"Explain how to preprocess text data for a machine learning model.\"\n",
    "\n",
    "`Improved Prompt`: \"List the steps involved in preprocessing text data for a machine learning model and describe each step in detail.\"\n",
    "\n",
    "`Finally Developed Prompt`: \"Begin with explaining why preprocessing text data is important for machine learning. Then detail the steps such as tokenization, removal of stop words, and normalization of text. Conclude with how these steps contribute to improving model accuracy.\"\n",
    "\n",
    "\n",
    "`Desired Answer from the LLM:`\n",
    "\n",
    "Preprocessing text data is crucial for machine learning models because it converts raw text into a manageable and clean format that enhances model training efficiency and effectiveness. Here are the key steps:\n",
    "1. **Tokenization:** This involves splitting text into sentences or words. It helps in structuring the text into smaller, manageable units.\n",
    "2. **Removal of Stop Words:** Stop words (e.g., 'and', 'the', etc.) are frequently occurring words that add little value in text analysis. Removing them focuses the analysis on significant words.\n",
    "3. **Normalization:** This step includes converting all text to lower case, removing punctuations, and correcting typos. This standardizes the text, making it easier for the model to process.\n",
    "These preprocessing steps are important as they reduce the noise in the data, allowing the machine learning model to focus on the meaningful content, thus improving accuracy.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVgTjwA0IzKekrQoMziCmDXjO10QKjdDdzK1Oj8bZToPOI6VjVzTKXZ6vnWvAGOdVnWznJK2ZZjfBuTLojobayI_yrvlFzE3dCErF2j5wKLGFWAkuGP9-r-hMrqFivnjYhbCIu7HFINSmHu4wUjlKHfJxWHZ8Y7CYUowWvxTeRJhQEAUswGh2fUd3VHA/s2500/chainofthought.png\" />\n",
    "</p>\n",
    "\n",
    "\n",
    "#### 4.4 : Generate Knowledge Prompting\n",
    "\n",
    "[Link to the paper](https://arxiv.org/pdf/2110.08387.pdf)\n",
    "\n",
    "- Summary:\n",
    "Generate knowledge prompting involves the model generating new insights or synthesizing information to enrich its responses. This technique is used when the task benefits from the creation of novel content or insights that extend beyond the directly available information.\n",
    "\n",
    "- Example for a Coding Task:\n",
    "\n",
    "`User Prompt` : \"How can I improve the performance of a Python script?\"\n",
    "\n",
    "`Improved Prompt `: \"Consider common performance issues in Python scripts. Generate insights on optimizing Python code.\"\n",
    "\n",
    "`Finally Developed Prompt`: \"Identify common performance bottlenecks in Python scripts, such as loop inefficiencies and excessive memory usage. Provide advanced tips on how to optimize these areas using Python code examples, focusing on techniques like using list comprehensions instead of loops and memory profiling tools.\"\n",
    "\n",
    "`Desired Answer from the LLM:`\n",
    "\n",
    "Improving the performance of a Python script involves addressing several potential bottlenecks:\n",
    "1. **Optimize Loops:** Replace traditional for-loops with list comprehensions where possible, as they are generally faster and more efficient.\n",
    "   Example: Use `[x*x for x in range(1000)]` instead of creating an empty list and appending squared values in a loop.\n",
    "2. **Memory Usage:** Utilize memory profiling tools like `memory_profiler` to identify and minimize excessive memory usage.\n",
    "   Example: Use `@profile` decorator to monitor memory usage of functions.\n",
    "3. **Use Efficient Data Structures:** Opt for data structures like `sets` or `dictionaries` when you need fast lookups.\n",
    "These strategies can significantly enhance the speed and efficiency of your Python scripts, making them perform better especially in large-scale applications.\n",
    "\n",
    "\n",
    "#### 4.5 : Prompt Chaining\n",
    "\n",
    "[Link to the document](https://docs.anthropic.com/claude/docs/chain-prompts)\n",
    "\n",
    "- Summary:\n",
    "Prompt chaining involves creating a sequence of queries where the answer or information from one query is used to inform or generate the next query. This method is ideal for exploring topics in depth or when one answer naturally leads to another question.\n",
    "\n",
    "- Example for a Machine Learning Task:\n",
    "\n",
    "`User Prompt`: \"What are decision trees in machine learning?\"\n",
    "\n",
    "`Improved Prompt`: \"After explaining decision trees, ask about their advantages over other machine learning algorithms.\"\n",
    "\n",
    "`Finally Developed Prompt`: \"Start by defining decision trees in the context of machine learning. Next, based on the definition, ask how decision trees handle both numerical and categorical data compared to other algorithms.\"\n",
    "\n",
    "`Desired Answer from the LLM`:\n",
    "Decision trees are a type of supervised learning algorithm that is used for both classification and regression tasks. They model decisions and their possible consequences as a tree-like structure. In machine learning, a decision tree makes decisions by splitting data into branches based on feature values.\n",
    "\n",
    "Given their structure, decision trees naturally handle both numerical and categorical data. Unlike many algorithms that require all input data to be numeric, decision trees can split nodes on categorical data using techniques like Gini impurity or entropy, making them versatile for various types of data. This advantage allows decision trees to be used in diverse scenarios without the need for extensive data preprocessing that some other algorithms require.\n",
    "\n",
    "\n",
    "#### 4.5 : Tree of Thoughts\n",
    "\n",
    "[Link to the paper](https://arxiv.org/abs/2305.10601)\n",
    "\n",
    "\n",
    "- Summary:\n",
    "Tree of thoughts uses a structured approach where each branch of the initial query expands into more detailed sub-questions. This technique systematically explores different aspects of a topic, similar to creating a mind map through dialogue.\n",
    "\n",
    "The method is complicated, and works as follows:\n",
    "\n",
    "1.  First, build a maieutic tree, where each node is a statement that could be true or false:\n",
    "    - Start with a multiple-choice question or true/false statement (e.g. War cannot have a tie)\n",
    "    - For each possible answer to the question, use the model to generate a corresponding explanation (with a prompt like War cannot have a tie? True, because)\n",
    "    - Then, prompt the model with the question and the generated explanation, and ask it to produce the answer. If reversing the explanation (with a prefix like It is wrong to say that {explanation}) reverses the answer, then the explanation is considered 'logically integral.'\n",
    "    - If an explanation is not logically integral, then repeat the above process recursively, with each explanation turned into a True or False question, and generate more explanations for each new question.\n",
    "    - After all of the recursive explaining is done, you end up with a tree of explanations, where each leaf on the tree has the property that reversing the explanation reverses the model's answer.\n",
    "2. Second, convert the tree into a graph of relations:\n",
    "    - For each node in the tree, calculate the model's relative belief in each node (inferred from the probability of getting an answer of True to given an explanation)\n",
    "    - For each pair of nodes in the tree, use the model to identify whether they are entailed (implied) or contradicted\n",
    "3. Third, find the most consistent set of beliefs and take those to be true\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://cookbook.openai.com/images/maieutic_fig6.png\" />\n",
    "</p>\n",
    "\n",
    "\n",
    "- Example for a Coding Task:\n",
    "\n",
    "`User Prompt`: \"How do I secure a web application?\"\n",
    "\n",
    "`Improved Prompt`: \"Explain the fundamental aspects of web security. Then, based on this overview, branch out to specific strategies such as data encryption, user authentication, and input validation.\"\n",
    "\n",
    "`Finally Developed Prompt`: \"Start by outlining the key components of securing a web application. Next, ask how to implement data encryption, follow up with the methods for user authentication, and conclude with best practices for input validation.\"\n",
    "\n",
    "`Desired Answer from the LLM:`\n",
    "Securing a web application involves several key components:\n",
    "\n",
    "1. **Data Encryption:** This ensures that sensitive data transmitted over networks is converted into a secure format that is nearly impossible to decrypt without the correct keys. Implement SSL/TLS to encrypt all communication between users and the server. Use encryption algorithms like AES for encrypting stored data.\n",
    "\n",
    "2. **User Authentication:** This process verifies if a user is who they claim to be. Implement multi-factor authentication (MFA) using a combination of something the user knows (password), something the user has (security token), and something the user is (biometric verification).\n",
    "\n",
    "3. **Input Validation:** Protect the application from malicious data inputs that could cause security vulnerabilities. Use server-side validation to ensure all incoming data is checked for type, length, format, and range.\n",
    "\n",
    "By addressing these areas, a web application can significantly enhance its security posture and protect against common vulnerabilities and attacks.\n",
    "\n",
    "\n",
    "#### 4.5 : Directional Stimulus Prompting\n",
    "\n",
    "[Link to the paper](https://arxiv.org/abs/2302.11520)\n",
    "\n",
    "- Summary:\n",
    "Directional stimulus prompting is designed to guide the language model's focus towards a specific area of inquiry or analysis. This technique is useful when the user seeks information on a particular aspect of a broader topic, thereby streamlining the response to be more targeted.\n",
    "\n",
    "- Example for a Machine Learning Task:\n",
    "\n",
    "`User Prompt:` \"Tell me about neural networks.\"\n",
    "\n",
    "`Improved Prompt:` \"Focus on explaining the application of neural networks in image recognition.\"\n",
    "\n",
    "`Finally Developed Prompt`: \"Explain how neural networks are applied in the field of image recognition, detailing the role of convolutional layers and how they help in identifying features in images.\"\n",
    "\n",
    "`Desired Answer from the LLM:`\n",
    "Neural networks, particularly convolutional neural networks (CNNs), play a crucial role in image recognition tasks. CNNs use convolutional layers, which apply a series of filters to the input image to create feature maps. These feature maps highlight various aspects of the image, such as edges, textures, or specific objects, depending on the complexity of the model.\n",
    "\n",
    "In image recognition, these convolutional layers automatically learn to identify essential features without explicit programming for each feature. This capability makes CNNs highly effective for tasks like facial recognition, object detection, and even medical image analysis, where distinguishing subtle features is critical.\n",
    "\n",
    "\n",
    "#### 4.6 : ReAct Prompting\n",
    "\n",
    "[Link to the paper](https://arxiv.org/abs/2210.03629)\n",
    "\n",
    "- Summary:\n",
    "ReAct prompting involves prompting the model to reconsider or reevaluate its previous responses in light of new information, corrections, or a different perspective. This encourages adaptability and accuracy in the model's outputs.\n",
    "\n",
    "- Example for a Coding Task:\n",
    "\n",
    "`User Prompt`: \"What is the best language for web development?\"\n",
    "\n",
    "`Improved Prompt`: \"You mentioned Python; however, consider the popularity and features of JavaScript for web development.\"\n",
    "\n",
    "`Finally Developed Prompt`: \"Reevaluate the choice of Python for web development in light of JavaScriptâ€™s capabilities such as asynchronous programming with callbacks and promises, and its ubiquity in browser environments.\"\n",
    "\n",
    "`Desired Answer from the LLM:`\n",
    "While Python is a powerful language and offers frameworks like Django and Flask for web development, JavaScript is indeed more suited for client-side web development. JavaScript's support for asynchronous programming through callbacks and promises allows for more responsive web applications. Additionally, as the primary language supported by web browsers, JavaScript is indispensable for interactive websites. Its ecosystem, including frameworks like React and Angular, also makes it a robust choice for full-stack development.\n",
    "\n",
    "\n",
    "#### 4.7 : Graph Prompting\n",
    "\n",
    "[Link to the paper](https://arxiv.org/abs/2302.08043)\n",
    "\n",
    "- Summary:\n",
    "Graph prompting involves presenting the model with data in a structured format, such as graphs or tables, prompting it to analyze relationships or process information based on visual or structured cues. This is particularly useful for tasks that involve relational or comparative analysis.\n",
    "\n",
    "- Example for a Machine Learning Task:\n",
    "\n",
    "`User Prompt`: \"Analyze the performance of various machine learning models based on the given dataset.\"\n",
    "\n",
    "`Improved Prompt`: \"Given a graph of model accuracy rates for different machine learning models over five trials, identify which model consistently performs best across all trials.\"\n",
    "\n",
    "`Finally Developed Prompt`: \"Review the provided graph depicting accuracy rates (y-axis) for SVM, Random Forest, and Neural Network models (x-axis) across five different trials. Determine which model shows the highest consistency in performance and suggest potential reasons based on common characteristics of the models.\"\n",
    "\n",
    "`Desired Answer from the LLM:`\n",
    "From the graph, it is evident that the Random Forest model shows the highest consistency in performance across all five trials, maintaining an accuracy rate of above 90%. This consistency can be attributed to the model's ability to handle a variety of data features and its robustness against overfitting compared to SVM and Neural Networks. Random Forests are less likely to be influenced by outliers and noise, making them more reliable for diverse datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
